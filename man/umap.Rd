% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/umap.R
\name{umap}
\alias{umap}
\title{umap}
\usage{
umap(data, n_neighbors = 15L, n_components = 2L, metric = "euclidean",
  n_epochs = NULL, alpha = 1, init = "spectral", spread = 1,
  min_dist = 0.1, set_op_mix_ratio = 1, local_connectivity = 1L,
  bandwidth = 1, gamma = 1, negative_sample_rate = 5L, a = NULL,
  b = NULL, random_state = NULL, metric_kwds = dict(),
  angular_rp_forest = FALSE, verbose = FALSE)
}
\arguments{
\item{data}{data frame or matrix. input data.}

\item{n_neighbors}{integer. The size of local neighborhood 
(in terms of number of neighboring sample points) used for manifold 
approximation. Larger values result in more global views of the manifold, 
while smaller values result in more local data being preserved. In general 
values should be in the range 2 to 100.}

\item{n_components}{integer The dimension of the space to embed into. This 
defaults to 2 to provide easy visualization, but can reasonably be set to 
any integer value in the range 2 to 100.}

\item{metric}{character. The metric to use to compute distances in high 
dimensional space. If a string is passed it must match a valid predefined 
metric. If a general metric is required a function that takes two 1d arrays 
and returns a float can be provided. For performance purposes it is required 
that this be a numba jit'd function. Valid string metrics include: euclidean, 
manhattan, chebyshev, minkowski, canberra, braycurtis, mahalanobis, 
wminkowski, seuclidean, cosine, correlation, haversine, hamming, jaccard, 
dice, russelrao, kulsinski, rogerstanimoto, sokalmichener, sokalsneath, yule. 
Metrics that take arguments (such as minkowski, mahalanobis etc.) can have 
arguments passed via the metric_kwds dictionary. At this time care must be 
taken and dictionary elements must be ordered appropriately; this will 
hopefully be fixed in the future.}

\item{n_epochs}{integer The number of training epochs to use in optimization.}

\item{alpha}{numeric. The initial learning rate for the embedding optimization.}

\item{init}{character. How to initialize the low dimensional embedding. 
Options are: 'spectral' (use a spectral embedding of the fuzzy 1-skeleton),
'random' (assign initial embedding positions at random), 
* A numpy array of initial embedding positions.}

\item{spread}{numeric. The effective scale of embedded points. 
In combination with ``min_dist`` this determines how clustered/clumped the 
embedded points are.}

\item{min_dist}{numeric.  The effective minimum distance between embedded 
points. Smaller values will result in a more clustered/clumped embedding 
where nearby points on the manifold are drawn closer together, while larger 
values will result on a more even dispersal of points. The value should be 
set relative to the ``spread`` value, which determines the scale at which 
embedded points will be spread out.}

\item{set_op_mix_ratio}{numeric. Interpolate between (fuzzy) union and 
intersection as the set operation used to combine local fuzzy simplicial 
sets to obtain a global fuzzy simplicial sets. Both fuzzy set operations use 
the product t-norm. The value of this parameter should be between 0.0 and 
1.0; a value of 1.0 will use a pure fuzzy union, while 0.0 will use a pure 
fuzzy intersection.}

\item{local_connectivity}{integer The local connectivity required -- i.e. 
the number of nearest neighbors that should be assumed to be connected at a 
local level. The higher this value the more connected the manifold becomes 
locally. In practice, this should be not more than the local intrinsic 
dimension of the manifold.}

\item{bandwidth}{numeric. The effective bandwidth of the kernel if we view 
the algorithm as similar to Laplacian eigenmaps. Larger values induce more 
connectivity and a more global view of the data, smaller values concentrate 
more locally.}

\item{gamma}{numeric. Weighting applied to negative samples in low 
dimensional embedding optimization. Values higher than one will result in 
greater weight being given to negative samples.}

\item{negative_sample_rate}{numeric. The number of negative edge/1-simplex 
samples to use per positive edge/1-simplex sample in optimizing the low 
dimensional embedding.}

\item{a}{numeric. More specific parameters controlling the embedding. 
If NULL, these values are set automatically as determined by ``min_dist`` 
and ``spread``.}

\item{b}{numeric. More specific parameters controlling the embedding. 
If NULL, these values are set automatically as determined by ``min_dist`` 
and ``spread``.}

\item{random_state}{integer. If integer, random_state is the seed used by the 
random number generator; If NULL, the random number generator is the 
RandomState instance used by `np.random`.}

\item{metric_kwds}{reticulate dictionary. Arguments to pass on to the metric, 
such as the ``p`` value for Minkowski distance.}

\item{angular_rp_forest}{logical. Whether to use an angular random projection 
forest to initialise the approximate nearest neighbor search. This can be 
faster, but is mostly on useful for metric that use an angular style distance 
such as cosine, correlation etc. In the case of those metrics angular forests 
will be chosen automatically.}

\item{verbose}{logical. Controls verbosity of logging.}
}
\value{
matrix
}
\description{
Provides an interface to the UMAP algorithm implemented in Python.
}
\examples{
umap(as.matrix(iris[, 1:4]))
umap(iris[, 1:4])
}
\references{
Leland McInnes and John Healy (2018). UMAP: Uniform Manifold 
Approximation and Projection for Dimension Reduction. 
ArXiv e-prints 1802.03426.
}
